{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HUK Coding Challenge\n",
    "\n",
    "Die Aufgabe besteht in der Modellierung einer Kundenaffinität zum Abschluss einer KFZ-Versicherung."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from functools import reduce\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)-15s %(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_delimiter(filename):\n",
    "    \"\"\"\n",
    "    This function looks for the delimiter in a file.\n",
    "\n",
    "    Inputs:\n",
    "        - filename (str): path to specific file\n",
    "    Returns:\n",
    "        - delimiter (str)\n",
    "    \"\"\"\n",
    "    with open(filename, 'r', newline='') as file:\n",
    "        dialect = csv.Sniffer().sniff(file.read(1024))\n",
    "        return dialect.delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_path = 'data/input_data/'\n",
    "directories = [os.path.join(os.getcwd(), '..', input_folder_path)]\n",
    "file_list = []\n",
    "dataframes = []\n",
    "\n",
    "# search in all specified directories\n",
    "for directory in directories:\n",
    "    # list content of directory\n",
    "    file_names = os.listdir(os.path.join(os.getcwd(), '..', directory))\n",
    "    logger.info(f'Found files: {file_names}')\n",
    "    for each_file_name in file_names:\n",
    "        file_list.append(each_file_name)\n",
    "        # get filepath to relevant files\n",
    "        file_path = os.path.join(os.getcwd(), '..', directory, each_file_name)\n",
    "        # error handling for the one file using a different delimiter\n",
    "        delimiter = detect_delimiter(file_path)\n",
    "        if delimiter == ',':\n",
    "            current_df = pd.read_csv(file_path)\n",
    "            dataframes.append(current_df)\n",
    "        else:\n",
    "            current_df = pd.read_csv(file_path, delimiter=';')\n",
    "            dataframes.append(current_df)\n",
    "\n",
    "# Merge all dataframes into one\n",
    "df_merged = reduce(lambda left, right: pd.merge(left, right, on='id'), dataframes)\n",
    "\n",
    "# Deduplicate\n",
    "df_merged = df_merged.drop_duplicates()\n",
    "\n",
    "# Check wether data path exists\n",
    "if not os.path.exists('../data/raw_data/'):\n",
    "    os.makedirs('../data/raw_data/')\n",
    "\n",
    "# save merged dataframe as csv\n",
    "df_merged.to_csv('../data/raw_data/raw_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative Datenanalyse (EDA)\n",
    "\n",
    "Machen Sie sich mit dem Datensatz vertraut. Identifizieren Sie dabei mögliche Probleme sowie grundlegende statistische Zusammenhänge, welche für die anschließende Modellierung wichtig sein könnten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df_raw, title='Pandas Profiling Report on raw data')\n",
    "# open report from output.html file generated from this cell\n",
    "profile.to_file(\"../eda_output.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data\n",
    "\n",
    "- Number of variables:      12\n",
    "- Number of observations:   381109\n",
    "- Missing cells:            0\n",
    "- Missing cells %:          0%\n",
    "- Duplicate rows:           0\n",
    "- Categorical:              2\n",
    "- Numeric:                  8\n",
    "- Boolean:                  1\n",
    "- Variables:\n",
    "    - Fahrerlaubnis:                Highly imbalanced (97.8%)\n",
    "    - Vertriebskanal > Alter:       High correlation\n",
    "    - Vorversicherung > Vorschaden: High correlation\n",
    "    - Alter_Fzg > Vertriebskanal:   High correlation\n",
    "    - id:                           uniformly distributed & unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check wether data path exists\n",
    "if not os.path.exists('../data/cleaned_data/'):\n",
    "    os.makedirs('../data/cleaned_data/')\n",
    "\n",
    "# save merged dataframe as csv\n",
    "df_raw.to_csv('../data/cleaned_data/cleaned_data.csv')\n",
    "df_cleaned = df_raw.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Bereiten Sie, soweit für Ihre Modellierung nötig, die Variablen geeignet auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names of numerical columns\n",
    "column_names = df_cleaned.columns\n",
    "\n",
    "# Get categorical columns\n",
    "categorical_columns = df_cleaned.select_dtypes(include=\"object\").columns\n",
    "\n",
    "# Get numerical columns\n",
    "numerical_columns = df_cleaned.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Create pipeline for categorical columns\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create pipline for numerical columns with StandardScaler\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('standard_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create transformer for all columns\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('categorical_pipeline', categorical_pipeline, categorical_columns)#,\n",
    "    #('numerical_pipeline', numerical_pipeline, numerical_columns)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit and transform data\n",
    "df_cleaned = preprocessor.fit_transform(df_cleaned)\n",
    "\n",
    "# Convert to dataframe\n",
    "df_cleaned = pd.DataFrame(df_cleaned, columns=['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'Fahrerlaubnis', 'Regional_Code', 'Vorversicherung', 'Jahresbeitrag', 'Vertriebskanal', 'Kundentreue', 'id', 'Interesse', 'Alter'])\n",
    "\n",
    "# Put id column as first column\n",
    "# and Interesse as last column\n",
    "df_cleaned = df_cleaned[['id', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'Fahrerlaubnis', 'Regional_Code', 'Vorversicherung', 'Jahresbeitrag', 'Vertriebskanal', 'Kundentreue', 'Alter', 'Interesse']]                                             \n",
    "\n",
    "# change unnecessary floats to int\n",
    "float_columns = ['Fahrerlaubnis', 'Regional_Code', 'Vorversicherung', 'Vertriebskanal', 'Kundentreue', 'Alter', 'Interesse']\n",
    "df_cleaned[float_columns] = df_cleaned[float_columns].astype('int64')\n",
    "\n",
    "# Check wether data path exists\n",
    "if not os.path.exists('../data/encoded_data/'):\n",
    "    os.makedirs('../data/encoded_data/')\n",
    "\n",
    "# save merged dataframe as csv\n",
    "df_cleaned.to_csv('../data/encoded_data/encoded_data.csv')\n",
    "df_encoded = df_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellvergleich\n",
    "\n",
    "Entscheiden Sie sich für ein geeignetes Modell zur Prognose der Kundenaffinität. Erläutern Sie wie Sie dabei vorgehen und begründen Sie Ihre Entscheidung."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Kundenaffinität zum Abschluss einer Kfz-Versicherung vorherzusagen, empfehle ich die Verwendung eines binären Klassifikationsmodells, wie beispielsweise das logistische Regressionsmodell oder ein Random Forest Classifier. Beide Modelle eignen sich gut für diese Art von Prognoseaufgaben.\n",
    "\n",
    "Logistische Regression:\n",
    "Die logistische Regression ist eine weit verbreitete Methode zur Vorhersage von binären Ergebnissen. Sie modelliert die Wahrscheinlichkeit, dass eine Beobachtung einer bestimmten Klasse angehört, basierend auf einer Kombination von Eingangsvariablen. In diesem Fall könnten Merkmale wie Alter, Geschlecht, Fahrzeugtyp, Vorversicherungshistorie, Schadensfreiheitsklasse, geografischer Standort usw. als Eingangsvariablen dienen. Das Modell kann dann die Wahrscheinlichkeit schätzen, dass ein Kunde affin oder nicht affin ist und eine Entscheidungsgrenze festlegen, um die Vorhersage zu treffen.\n",
    "\n",
    "Random Forest Classifier:\n",
    "Ein Random Forest Classifier ist ein Ensemble-Modell, das aus mehreren Entscheidungsbäumen besteht. Jeder Baum wird auf einem zufälligen Teil des Datensatzes trainiert, und die Vorhersage erfolgt durch Abstimmung der Vorhersagen der einzelnen Bäume. Random Forests sind in der Regel robust gegenüber Overfitting und können gut mit einer Mischung aus kategorischen und numerischen Variablen umgehen. Sie können auch die wichtigsten Merkmale identifizieren, die zur Vorhersage beitragen.\n",
    "\n",
    "Bei der Auswahl des Modells sind folgende Faktoren zu berücksichtigen:\n",
    "\n",
    "Datenverfügbarkeit: Verfügbarkeit der Daten überprüfen. Sicherstellen, dass ausreichend Daten vorhanden sind, um ein zuverlässiges Modell zu trainieren, und dass die relevanten Merkmale erfasst werden.\n",
    "\n",
    "Interpretierbarkeit: Wenn es wichtig ist, die Vorhersage des Modells zu verstehen und zu erklären, könnte die logistische Regression die bessere Wahl sein. Die Koeffizienten des Modells können direkt interpretiert werden, um den Einfluss der einzelnen Merkmale zu verstehen.\n",
    "\n",
    "Leistung: Gründliche Evaluation der Modelle durchführen, indem geeignete Leistungsmetriken wie Genauigkeit, Präzision, Recall oder den Flächenwert unter der ROC-Kurve (AUC-ROC) verwendet werden. Geeignetes Modell mit den besten Vorhersageergebnissen für Ihre spezifische Anwendung auswählen.\n",
    "\n",
    "Dateninterpretation: Wenn interessant ist, zu verstehen, welche Merkmale am stärksten zur Vorhersage beitragen, könnte der Random Forest Classifier von Vorteil sein. Er kann die wichtigsten Merkmale identifizieren und Einblicke in die Beziehung zwischen den Merkmalen und der Zielvariable liefern.\n",
    "\n",
    "Es ist grundsätzlich sinnvoll im Prozess verschiedene Modelle miteinander zu vergleichen, diese Code Challenge wird allerdings mit einem Random Forrest Classifier umgesetzt werden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellbuilding\n",
    "\n",
    "1. Trainieren Sie das von Ihnen gewählte Modell. Wählen Sie geeignete Metriken um die Güte des finalen Modells zu beurteilen.\n",
    "2. Zeigen Sie, welche Variablen und Zusammenhänge für Ihre finales Modell relevant sind.\n",
    "3. Überlegen Sie sich (ohne Umsetzung) wie Sie Ihr Modell weiter optimieren können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest classifier model \n",
    "# and select suitable hyperparameters\n",
    "# and metrics to view the models performance\n",
    "\n",
    "# Split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_encoded.drop('Interesse', axis=1), df_encoded['Interesse'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Evaluate model on train set\n",
    "logger.info(f'Train Accuracy: {accuracy_score(y_train, y_train_pred)}')\n",
    "logger.info(f'Train Precision: {precision_score(y_train, y_train_pred)}')\n",
    "logger.info(f'Train Recall: {recall_score(y_train, y_train_pred)}')\n",
    "logger.info(f'Train F1: {f1_score(y_train, y_train_pred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the models performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "logger.info(f'Tets Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "logger.info(f'Test Precision: {precision_score(y_test, y_pred)}')\n",
    "logger.info(f'Test Recall: {recall_score(y_test, y_pred)}')\n",
    "logger.info(f'Test F1: {f1_score(y_test, y_pred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Score:\n",
    "Accuracy_score calculates the percentage of correct predictions made by the model out of all the predictions. It is calculated by dividing the number of correct predictions by the total number of predictions. A high accuracy score indicates a high overall predictive performance of the model. However, accuracy alone might not be sufficient if the dataset is imbalanced.\n",
    "\n",
    "Precision Score:\n",
    "Precision_score measures the proportion of correctly predicted positive instances out of all instances predicted as positive. It is calculated by dividing the number of true positives by the sum of true positives and false positives. Precision focuses on the quality of positive predictions. A high precision score indicates a low false positive rate, meaning that when the model predicts a positive class, it is likely to be correct.\n",
    "\n",
    "Recall Score:\n",
    "Recall_score, also known as sensitivity or true positive rate, measures the proportion of correctly predicted positive instances out of all actual positive instances. It is calculated by dividing the number of true positives by the sum of true positives and false negatives. Recall focuses on the model's ability to find all positive instances without missing any. A high recall score indicates a low false negative rate, meaning that the model can correctly identify a large proportion of positive instances.\n",
    "\n",
    "F1 Score:\n",
    "The F1_score is the harmonic mean of precision and recall. It provides a balance between precision and recall and is useful when you want to consider both false positives and false negatives. It is calculated as 2 * ((precision * recall) / (precision + recall)). The F1 score is a single metric that combines precision and recall. A high F1 score indicates good overall performance when considering both precision and recall.\n",
    "\n",
    "In summary, while accuracy_score provides an overall performance measure, precision_score, recall_score, and f1_score offer insights into different aspects of the model's performance. Consider your specific requirements and the nature of your problem to determine which metric(s) are most important for your evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse Transform to get original values\n",
    "X_test_inv = preprocessor.named_transformers_['categorical_pipeline'].inverse_transform(X_test[['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7']])\n",
    "\n",
    "# Add to dataframe X_train\n",
    "X_test['Alter_Fzg'] = X_test_inv[:, 0]\n",
    "X_test['Vorschaden'] = X_test_inv[:, 1]\n",
    "X_test['Geschlecht'] = X_test_inv[:, 2]\n",
    "\n",
    "# Drop lag columns\n",
    "X_test = X_test.drop(['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7'], axis=1)\n",
    "\n",
    "# Add actual values from y_train to dataframe\n",
    "X_test['Interesse'] = y_test\n",
    "\n",
    "# Add train predictions to dataframe\n",
    "X_test['Preds'] = y_pred\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check wether data path exists\n",
    "if not os.path.exists('../models/'):\n",
    "    os.makedirs('../models/')\n",
    "\n",
    "# Save model with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "with open(f'../models/model_{timestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible strategies to optimize the Random Forrest Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Feature Selection:__\n",
    "\n",
    "Evaluate the importance of each feature in your model and consider removing less informative or highly correlated features. This can be done by examining the feature importances provided by the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the most important features\n",
    "feature_importances = pd.DataFrame(model.feature_importances_, index=X_train.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Hyperparameter Tuning:__ \n",
    "\n",
    "Random forests have various hyperparameters that can be tuned to improve performance and reduce overfitting. Some key hyperparameters include the number of trees (n_estimators), the maximum depth of the trees (max_depth), and the minimum number of samples required to split an internal node (min_samples_split). Using techniques like grid search or randomized search, you can find optimal hyperparameter values that balance model complexity and performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Regularization:__ \n",
    "\n",
    "Random forests have regularization techniques like subsampling (using a subset of samples for training each tree) and feature subspace sampling (using a subset of features for each split). These techniques can help reduce overfitting by introducing additional randomness into the model.\n",
    "\n",
    "__Subsampling (Bootstrap Aggregating or Bagging):__\n",
    "In a random forest, each decision tree is trained on a different bootstrap sample obtained by randomly selecting a subset of the original training data with replacement. This means that each tree is trained on a different subset of the data, allowing them to capture different patterns. By aggregating the predictions of all trees, the random forest reduces the variance and prevents overfitting. Subsampling introduces additional randomness into the model, improving its generalization.\n",
    "\n",
    "__Feature Subspace Sampling:__\n",
    "For each split in a decision tree within a random forest, only a random subset of features is considered. Instead of evaluating all features at each split, a limited set of features is randomly selected. This technique is also called feature bagging or random subspace method. By using only a subset of features for each tree, the random forest encourages diversity among the trees and reduces the correlation between them. This helps prevent overfitting and improves the robustness of the model.\n",
    "\n",
    "**Regularization techniques like subsampling and feature subspace sampling are inherent in the random forest algorithm and do not require explicit user intervention. However, you can adjust the hyperparameters max_features and max_samples to fine-tune the regularization strength and control the trade-off between model complexity and performance.**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Cross-Validation:__ \n",
    "Instead of evaluating the model solely on the training set, perform cross-validation to assess its performance on multiple train-test splits. This helps provide a more robust estimate of the model's performance and can indicate if it is overfitting.\n",
    "\n",
    "The advantage of using cross-validation is that it provides a more robust estimate of the model's performance compared to a single train-test split. It helps assess the model's ability to generalize to unseen data and reduces the influence of the specific data split on the evaluation.\n",
    "To perform cross-validation in scikit-learn, you can use the cross_val_score function or the cross_validate function, specifying the number of folds (cv parameter) and the desired evaluation metric. These functions handle the data splitting and model evaluation automatically, making it easier to perform cross-validation with random forests."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Increase Training Data:__ \n",
    "\n",
    "If possible, obtain more training data to provide a broader representation of the underlying patterns. A larger dataset can help the model generalize better and reduce overfitting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Early Stopping:__ \n",
    "\n",
    "Monitor the model's performance on a validation set during training and stop training early if the performance starts to degrade. This prevents the model from overfitting to the training data excessively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest classifier model\n",
    "# select suitable hyperparamters with grit search\n",
    "# select metrics to view the models performance\n",
    "\n",
    "# Get categorical columns\n",
    "categorical_columns = df_cleaned.select_dtypes(include=\"object\").columns\n",
    "\n",
    "# Get numerical columns\n",
    "numerical_columns = df_cleaned.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Create pipeline for categorical columns\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create pipline for numerical columns with StandardScaler\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('standard_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create transformer for all columns\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('categorical_pipeline', categorical_pipeline, categorical_columns)#,\n",
    "    #('numerical_pipeline', numerical_pipeline, numerical_columns)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit and transform data\n",
    "df_cleaned = preprocessor.fit_transform(df_cleaned)\n",
    "\n",
    "# Convert to dataframe\n",
    "df_cleaned = pd.DataFrame(df_cleaned, columns=['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'Fahrerlaubnis', 'Regional_Code', 'Vorversicherung', 'Jahresbeitrag', 'Vertriebskanal', 'Kundentreue', 'id', 'Interesse', 'Alter'])\n",
    "\n",
    "# Put id column as first column\n",
    "# and Interesse as last column\n",
    "df_cleaned = df_cleaned[['id', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'Fahrerlaubnis', 'Regional_Code', 'Vorversicherung', 'Jahresbeitrag', 'Vertriebskanal', 'Kundentreue', 'Alter', 'Interesse']]\n",
    "\n",
    "# change unnecessary floats to int\n",
    "float_columns = ['Fahrerlaubnis', 'Regional_Code', 'Vorversicherung', 'Vertriebskanal', 'Kundentreue', 'Alter']\n",
    "df_cleaned[float_columns] = df_cleaned[float_columns].astype('int64')\n",
    "\n",
    "df_encoded = df_cleaned.copy()\n",
    "\n",
    "# Train a random forest classifier model\n",
    "# select suitable hyperparamters with grit search\n",
    "# select metrics to view the models performance\n",
    "\n",
    "# train, test, split\n",
    "# Split data into train and test\n",
    "X = df_encoded.drop(['Interesse'], axis=1)\n",
    "y = df_encoded['Interesse']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the parameter grid based on the results of random search\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'max_features': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_samples_leaf': [3, 4, 5, 6, 7],\n",
    "    'min_samples_split': [8, 10, 12, 14, 16],\n",
    "    'n_estimators': [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
    "                            cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters\n",
    "grid_search.best_params_\n",
    "\n",
    "# Get best estimator\n",
    "best_grid = grid_search.best_estimator_\n",
    "\n",
    "# Get predictions\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "# Get metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {f1}')\n",
    "\n",
    "# Check wether data path exists\n",
    "if not os.path.exists('../models/'):\n",
    "    os.makedirs('../models/')\n",
    "\n",
    "# save model\n",
    "pickle.dump(best_grid, open('../models/model.pkl', 'wb'))\n",
    "\n",
    "# save preprocessor\n",
    "pickle.dump(preprocessor, open('../models/preprocessor.pkl', 'wb'))\n",
    "\n",
    "# save metrics\n",
    "metrics = {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "pickle.dump(metrics, open('../models/metrics.pkl', 'wb'))\n",
    "\n",
    "# save predictions\n",
    "predictions = {'y_pred': y_pred}\n",
    "pickle.dump(predictions, open('../models/predictions.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huk_coding_challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "913db32498f814a7e956b858dc9ab26e0e62ace447c646841c6d05c67a28a2e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
